---
title: "Approximating the Viterbi path of triplet Markov chains"
date: 2025-08-23
---

In this post we will introduce the problem of finding the Viterbi path of triplet Markov chains. Then we will describe one way to approximate the path using methods from variational infrence.

## Triplet Markov chains and Viterbi path

{% raw %}
Let $$\{Z_t\}_t$$ be a Markov chain with an initial probability distribution $$\pi$$ and (homogeneous) transition matrix $$p$$. A triplet Markov chain can be described when we have $$Z_t = (U_t,X_t,Y_t)$$. Introducing the extra variables has the following goal --- we can describe a fixed data variable $$\textbf{y}$$, do inference to find properties about $$\textbf{X}$$ that we are interested in while incorporating the effects of a nuisance variable $$\textbf{U}$$ in our model. Triplet Markov chains generalise pairwise Markov chains that have been both studied by JÃ¼ri Lember in Tartu University. It is easy to see that these models generalise Markov chains and hidden Markov models.

Let us fix the observations $$\textbf{y} = (y_t)_{t=1}^T$$. We can describe the process $$ \{U_t,X_t | \textbf{y} \}_t $$ as an discrete inhomogeneous pairwise Markov chain with a transition matrix at timestep $$t$$ noted by $$p_t$$. We can introduce the{% endraw %}  **Viterbi path problem** {% raw %} as finding the argmax $$\textbf{x}^*$$ for the following problem
\begin{equation}
\max_{\textbf{x}} \sum_{\textbf{u}} p_t(\textbf{u},\textbf{x})\tag{1}
\label{eq:test}
\end{equation}
{% endraw %}

This is known to be a NP hard problem, so we introduce a way to approximate the Viterbi path.

## Variational infrence on discrete probability distributions

As concluded in the previous chapter, we are interested in discrete probability distributions. This makes our life a bit easier than what others usually focus on [in literature](https://cse.buffalo.edu/faculty/mbeal/thesis/).

We approximate the Viterbi path by creating a variational distribution $$q$$ that approximates the true distribution $$p$$. Let us clarify which $$p$$ we are talking about by introducing the concept of [ELBO](https://en.wikipedia.org/wiki/Evidence_lower_bound) (evidence lower bound). Our wish is to minimise the following Kullback-Leibler divergence
{% raw %}$$ D\left[ q \| p \right]. $${% endraw %}
It is well known that the minimal $$q$$ is in fact $$p$$. But this still leaves us with the NP hard problem. So we choose to add some constraints that would make finding the Viterbi path tractable. The two constraints we look at are
* $$q(\textbf{u},\textbf{u}) = q(\textbf{u})q(\textbf{x})$$ inducing the belief propagation algorithm
* $$q(\textbf{u},\textbf{x}) = \prod_{t=1}^T$$ inducing the variational message passing algorithm.

